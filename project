# Imports here
import numpy as np
import matplotlib.pyplot as plt
import json
import torch
from torch import nn, optim
import torch.nn.functional as F
from torch.autograd import Variable
import torchvision
from torchvision import datasets, transforms, models
from collections import OrderedDict
from PIL import Image

#LOAD DATA
data_dir = 'flowers'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'

# TODO: Define your transforms for the training, validation, and testing sets
data_transforms_train = transforms.Compose([transforms.RandomRotation(20), 
                                            transforms.RandomResizedCrop(224), 
                                            transforms.RandomHorizontalFlip(),
                                            transforms.ToTensor(),
                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
data_transforms_valid_test = transforms.Compose([transforms.Resize(256),
                                                     transforms.CenterCrop(224),
                                                     transforms.ToTensor(),
                                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

# TODO: Load the datasets with ImageFolder
train_dataset= datasets.ImageFolder(train_dir, transform = data_transforms_train)
valid_dataset=  datasets.ImageFolder(valid_dir, transform = data_transforms_valid_test )
test_dataset= datasets.ImageFolder(test_dir, transform= data_transforms_valid_test)

# TODO: Using the image datasets and the trainforms, define the dataloaders
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle = True)
validloader = torch.utils.data.DataLoader(valid_dataset, batch_size = 32, shuffle = False)
testloader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = False)


with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)
    
# TODO: Build and train your network

#Install cuda stuff for gpu

device = torch.device ("cuda" if torch.cuda.is_available() else "cpu")

model = models.vgg11(pretrained= True)

#freeze feature parameters
for k in model.parameters():
    k.requires_grad = False
    
#Define new classifier
classifier = nn.Sequential(nn.Linear(25088,4096),
                           nn.ReLU(),
                           nn.Dropout(p=0.5),
                           nn.Linear(4096, 2048),
                           nn.ReLU(),
                           nn.Dropout(p=0.5), 
                           nn.Linear(2048, 1024),
                           nn.ReLU(),
                           nn.Dropout(p=0.5),
                           nn.Linear(1024, 102),
                           nn.LogSoftmax(dim=1))
model.classifier = classifier

#Loss: negative log likelihood  
criterion = nn.NLLLoss() 

#Optimizer:Adam
optimizer = optim.Adam(model.classifier.parameters(), lr = 0.003)

#MEMO: put this in GPU 
model.to(device)

#TRAINING THE NETWORK
epochs = 10
steps = 0
train_loss= 0
print_every = 5



#TRAINING TIME

for ii in range(epochs): 
    for images, labels in trainloader:
        steps += 1
        
        #Move images and labels to the gpu
        images, labels = images.to(device), labels.to(device)
        
        #Zero our gradients
        optimizer.zero_grad()
        
        #Forward pass
        logprob = model.forward(images)
        loss = criterion(logprob, labels)
        
        #Backprop
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
        
        #VALIDATION TIME
    else:
        valid_loss = 0
        accuracy = 0
        
        model.eval()
        #The model has to be in evaluation mode now
       
        with torch.no_grad():
            
            for images, labels in validloader:
                images, labels = images.to(device), labels.to(device)
                logprob = model.forward(images)
                
                loss = criterion(logprob, labels)
                valid_loss += loss.item()
                
                #Calculate accuracy
                prob = torch.exp(logprob)
                top_prob, top_class = prob.topk(1, dim=1)
                comparison = top_class == labels.view(*top_class.shape)
                accuracy += torch.mean(comparison.type(torch.FloatTensor)).item()
            
        print(f"Epoch {ii+1}/{epochs}.. "
            f"Train loss: {train_loss/print_every:.3f}.. "
            f"Validation loss: {valid_loss/len(validloader):.3f}.. "
            f"Validation accuracy: {accuracy/len(validloader):.3f}")
        train_loss = 0
        #After validation, the model goes back into training mode
        model.train()
